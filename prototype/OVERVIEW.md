# ğŸ”¬ Prototype Code Overview

This document provides a complete overview of the prototype codebase extracted from Jupyter notebooks.

## ğŸ“‹ Table of Contents

1. [Project Background](#project-background)
2. [Complete Workflow](#complete-workflow)
3. [Directory Structure](#directory-structure)
4. [Version History](#version-history)
5. [Quick Start Guide](#quick-start-guide)
6. [Technical Architecture](#technical-architecture)
7. [Key Innovations](#key-innovations)

---

## ğŸ¯ Project Background

This prototype implements a complete pipeline for **topology-aware character instance segmentation**:

- **Goal**: Detect exact character shapes including topological features (holes in O, P, A, etc.)
- **Approach**: Synthetic data generation + Mask R-CNN training
- **Innovation**: Pixel-perfect polygon annotations for precise text removal
- **Application**: Clean text removal from images without disturbing surrounding content

---

## ğŸ”„ Complete Workflow

```
1. FONT DOWNLOAD
   â”œâ”€â†’ Download Google Fonts (all or curated)
   â””â”€â†’ Store in fonts/ directory

2. DATA GENERATION
   â”œâ”€â†’ Load fonts
   â”œâ”€â†’ Generate synthetic text images
   â”œâ”€â†’ Extract character polygons
   â””â”€â†’ Save images + CSV annotations

3. VALIDATION
   â”œâ”€â†’ Create binary masks
   â”œâ”€â†’ Overlay polygon visualizations
   â””â”€â†’ Verify annotation quality

4. TRAINING
   â”œâ”€â†’ Load dataset (images + polygons)
   â”œâ”€â†’ Train Mask R-CNN
   â”œâ”€â†’ Save checkpoints
   â””â”€â†’ Monitor loss

5. INFERENCE
   â”œâ”€â†’ Load trained model
   â”œâ”€â†’ Process new images
   â”œâ”€â†’ Generate predictions
   â””â”€â†’ Visualize results
```

---

## ğŸ“ Directory Structure

```
prototype/
â”œâ”€â”€ font_download/              # Step 1: Font acquisition
â”‚   â”œâ”€â”€ download_all_fonts.py          # All Google Fonts
â”‚   â”œâ”€â”€ download_curated_fonts.py      # 100+ popular fonts â­
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ generators/                 # Step 2: Synthetic data generation
â”‚   â”œâ”€â”€ generator_v5_mask_based.py     # Mask-based collision
â”‚   â”œâ”€â”€ generator_v6_shapely.py        # Shapely polygon-based â­
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ validation/                 # Step 3: Quality verification
â”‚   â”œâ”€â”€ create_binary_masks.py         # Binary mask visualizer
â”‚   â”œâ”€â”€ visualize_polygons.py          # Polygon overlay â­
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ training/                   # Step 4: Model training
â”‚   â”œâ”€â”€ train_maskrcnn_v1_2.py         # Mask R-CNN training â­
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ inference/                  # Step 5: Prediction
â”‚   â”œâ”€â”€ inference_v1_1.py              # Model inference â­
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ README.md                   # Main documentation
```

â­ = Recommended version

---

## ğŸ“š Version History

### Font Download
- **Variant 1**: Downloads all Google Fonts (~1GB, thousands of fonts)
- **Variant 2**: Downloads 100+ curated popular fonts (recommended)

### Data Generators
- **v5**: Mask-based collision detection (faster, good accuracy)
- **v6**: Shapely polygon-based collision (slower, excellent accuracy) âœ… RECOMMENDED

### Validation Tools
- **Variant 1**: Binary mask visualizer (quick overview)
- **Variant 2**: Polygon overlay visualizer (detailed inspection) âœ… RECOMMENDED

### Training
- **v1.2**: Industry-standard checkpoint format
  - Resume training mode
  - Fine-tuning mode
  - Train from scratch mode

### Inference
- **v1.1**: Compatible with v1.2 training output
  - Auto-detects num_classes
  - Generates binary masks + overlays

---

## ğŸš€ Quick Start Guide

### Prerequisites
```bash
pip install torch torchvision opencv-python numpy pillow faker requests shapely tqdm matplotlib
```

### Step-by-Step

#### 1ï¸âƒ£ Download Fonts (5 minutes)
```bash
cd font_download
python download_curated_fonts.py
```

#### 2ï¸âƒ£ Generate Dataset (30-60 minutes for 1000 images)
```bash
cd ../generators
# Edit config at top of file (paths, image count, etc.)
python generator_v6_shapely.py
```

#### 3ï¸âƒ£ Validate Quality (Optional, 5 minutes)
```bash
cd ../validation
# Edit paths in script
python visualize_polygons.py
# Check output for quality issues
```

#### 4ï¸âƒ£ Train Model (2-8 hours depending on dataset size)
```bash
cd ../training
# Edit config (DATA_DIR, NUM_EPOCHS, etc.)
python train_maskrcnn_v1_2.py
```

#### 5ï¸âƒ£ Run Inference (Minutes)
```bash
cd ../inference
# Edit config (MODEL_PATH, INPUT_DIR, etc.)
python inference_v1_1.py
```

---

## ğŸ—ï¸ Technical Architecture

### Data Generation Pipeline

```
Background Image (Picsum/Solid)
    â†“
Font Selection (Random)
    â†“
Word Generation (Faker/Random)
    â†“
Character Rendering (PIL)
    â†“
Collision Detection (Masks/Shapely)
    â†“
Placement & Rotation
    â†“
Polygon Extraction (OpenCV findContours)
    â†“
CSV Annotation + PNG Image
```

### Training Pipeline

```
CSV Annotations â†’ Polygon Parsing
                     â†“
                Binary Masks (cv2.fillPoly)
                     â†“
                Bounding Boxes
                     â†“
                PyTorch Dataset
                     â†“
                DataLoader
                     â†“
           Mask R-CNN (ResNet-50 FPN)
                     â†“
            Loss Calculation
                     â†“
            Backpropagation
                     â†“
            Checkpoint Saving
```

### Inference Pipeline

```
Input Image (any size)
    â†“
RGB Conversion
    â†“
Tensor Transform
    â†“
Model Forward Pass
    â†“
Score Filtering (threshold)
    â†“
Mask Post-processing
    â†“
Binary Mask + Overlay Visualization
```

---

## ğŸ’¡ Key Innovations

### 1. Topology-Aware Segmentation
- Uses `cv2.findContours()` with proper hierarchy
- Preserves holes in characters (O, P, A, B, D, etc.)
- More accurate than bounding-box approaches

### 2. Advanced Collision Detection
- **Pre-rotation check**: Prevents character overlap within words
- **Post-rotation check**: Validates rotated characters don't overlap
- **Global polygon tracking (v6)**: Prevents overlap between different words
- **Shapely intersection (v6)**: Geometric precision

### 3. Automatic Spacing Adjustment
- Iterates through spacing values (0 to MAX_EXTRA_SPACING)
- Finds minimum spacing that prevents overlap
- Falls back to font size reduction if needed

### 4. Flexible Training Modes
- **From scratch**: COCO pretrained â†’ full training
- **Resume**: Continue interrupted training (preserves optimizer state)
- **Fine-tune**: Adapt existing model to new data (lower LR)

### 5. Smart Checkpoint Management
- Auto-detects checkpoint format (dict or state_dict)
- Infers num_classes from weights
- Versioned saving for comparison
- Reproducible with fixed seeds

---

## ğŸ¯ Configuration Summary

### Data Generation
```python
IMAGE_WIDTH = 1024              # Image dimensions
IMAGE_HEIGHT = 1024
NUM_IMAGES = 1000              # Dataset size
MIN_CHARS_PER_IMAGE = 100      # Minimum characters per image
MIN_FONT_SIZE = 28             # Font size range
MAX_FONT_SIZE = 56
CURVED_WORD_PROB = 0.3         # Probability of curved text
CONTRAST_THRESHOLD = 3.0       # Text visibility
```

### Training
```python
NUM_EPOCHS = 10                # Training duration
BATCH_SIZE = 2                 # Batch size (adjust for GPU)
LEARNING_RATE = 0.005          # Initial LR
SEED = 15107                   # Reproducibility
SAVE_EVERY_EPOCH = True        # Checkpoint frequency
```

### Inference
```python
SCORE_THRESHOLD = 0.5          # Detection confidence
```

---

## ğŸ“Š Performance Benchmarks

### Data Generation
- **v5**: 10-15 images/minute
- **v6**: 8-12 images/minute

### Training
- **GPU (RTX 3090)**: ~500 images/hour
- **GPU (GTX 1080)**: ~200 images/hour

### Inference
- **GPU (RTX 3090)**: ~0.1-0.2 sec/image
- **CPU**: ~2-5 sec/image

---

## ğŸ› Common Issues & Solutions

### Issue: No fonts found
**Solution**: Run font download script first

### Issue: Out of memory during training
**Solution**: Reduce BATCH_SIZE or use smaller images

### Issue: Low character count in generated images
**Solutions**:
- Increase MAX_PLACEMENT_ATTEMPTS
- Increase MAX_EXTRA_SPACING
- Decrease MIN_CHARS_PER_IMAGE

### Issue: Model not detecting characters
**Solutions**:
- Lower SCORE_THRESHOLD
- Check training data quality
- Train for more epochs
- Try fine-tuning instead of training from scratch

### Issue: Overlapping characters in dataset
**Solution**: Use generator_v6_shapely.py instead of v5

---

## ğŸ“ˆ Recommended Workflow

### For Research/Publications
1. Use generator_v6_shapely.py (highest accuracy)
2. Generate validation visualizations
3. Train multiple models with different seeds
4. Compare results across checkpoints
5. Use versioned checkpoint saving

### For Rapid Prototyping
1. Use generator_v5_mask_based.py (faster)
2. Use download_curated_fonts.py (smaller dataset)
3. Train with fewer epochs initially
4. Use fine-tuning for iterations

### For Production Deployment
1. Start with generator_v6_shapely.py
2. Extensive validation before training
3. Use fine-tuning on domain-specific data
4. Multiple model comparison with different architectures
5. Comprehensive testing on held-out set

---

## ğŸ”— Related Documentation

Each subdirectory contains detailed README files:
- `font_download/README.md` - Font acquisition details
- `generators/README.md` - Data generation configuration
- `validation/README.md` - Quality verification guide
- `training/README.md` - Training modes and troubleshooting
- `inference/README.md` - Prediction and visualization

---

## ğŸ“ Notes

1. **This is prototype code** preserved from Jupyter notebooks
2. **For production use**, refer to the modularized version in the main project
3. **All scripts are standalone** and can be run independently
4. **Each component is well-documented** with inline comments
5. **Configurations are at the top** of each file for easy modification

---

## ğŸ“ Learning Path

**Beginner**: Start with Quick Start Guide above
**Intermediate**: Read individual README files for each component
**Advanced**: Review source code with inline documentation
**Research**: See OVERVIEW.md for technical architecture and innovations

---

## ğŸ¤ Contributing

This is a research prototype. For improvements:
1. Test changes on small dataset first
2. Document modifications clearly
3. Compare results with baseline
4. Update relevant README files

---

## ğŸ“ Support

For questions about:
- **Setup**: See Quick Start Guide above
- **Configuration**: See README in relevant subdirectory
- **Troubleshooting**: See Common Issues section above
- **Architecture**: See Technical Architecture section above

---

**Last Updated**: November 2025
**Version**: Prototype 1.0
**Status**: Research Code - Preserved from Notebooks
